{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Image Retrieval - COSFIRE APPROACH\"\n",
        "date: today\n",
        "date-format: long\n",
        "author: \"Steven et al.\"\n",
        "format:\n",
        "  html:\n",
        "    toc: true\n",
        "    toc-depth: 3\n",
        "    toc-location: left\n",
        "    page-layout: full\n",
        "    theme:\n",
        "          light: flatly\n",
        "          dark: darkly\n",
        "    number-sections: true\n",
        "    smooth-scroll: true\n",
        "    code-fold: true\n",
        "    highlighting-style: github\n",
        "    self-contained: false\n",
        "execute:\n",
        "    echo: true\n",
        "    warning: false\n",
        "    enable: true\n",
        "\n",
        "title-block-banner: true\n",
        "---"
      ],
      "id": "4644d36e"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```{=html}\n",
        "<style type=\"text/css\">\n",
        "\n",
        "h1.title {\n",
        "  font-size: 20px;\n",
        "  color: White;\n",
        "  text-align: center;\n",
        "}\n",
        "h4.author { /* Header 4 - and the author and data headers use this too  */\n",
        "    font-size: 16px;\n",
        "  font-family: \"Source Sans Pro Semibold\", Times, serif;\n",
        "  color: Red;\n",
        "  text-align: center;\n",
        "}\n",
        "h4.date { /* Header 4 - and the author and data headers use this too  */\n",
        "  font-size: 16px;\n",
        "  font-family: \"Source Sans Pro Semibold\", Times, serif;\n",
        "  color: Red;\n",
        "  text-align: center;\n",
        "}\n",
        "\n",
        ".justify {\n",
        "  text-align: justify !important\n",
        "}\n",
        "\n",
        "/* Adjust width of the Quarto tab buttons */\n",
        ".panel-tabset .nav-link {\n",
        "    width: 250px; /* Adjust the width value to your preference */\n",
        "}\n",
        "\n",
        "\n",
        "</style>\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "------------------------------------------------------------------------\n",
        "\n",
        ":::{.column-page}\n",
        "\n",
        "::: {style=\"text-align:center\"}\n",
        "<h2>Image Retrieval by Hashing </h2>\n",
        ":::\n",
        "\n",
        "\n",
        "</br>\n",
        "\n",
        "### Introduction\n",
        "\n",
        "::: {.justify}\n",
        "This work develops a compact image hash code learning framework based on the COSFIRE filter banks for efficient similarity search and retrieval. Images are first passed through class-specific COSFIRE filters designed to activate on visually discriminative patterns. These feature vectors are input to a simple multi-layer perceptron (MLP)  network to learn binary hash codes that should capture the semantic similarity of the images, enabling efficient matching of hash codes of database images for fast retrieval. Our experiments on an image dataset demonstrate the potential of this straightforward approach for developing compact hash codes based rotation-invariant COSFIRE descriptors.  \n",
        "\n",
        "::: {.callout-tip}\n",
        "MLP is a type of artificial neural network consisting of multiple layers of neurons. The neurons in the MLP typically use nonlinear activation functions, allowing the network to learn complex patterns in data.\n",
        ":::\n",
        ":::\n",
        "\n",
        "\n",
        "### Data description\n",
        "\n",
        "::: {.justify}\n",
        "The input data consists of a set of descriptors extracted for each image using COSFIRE filters. Specifically, 50 COSFIRE filters are designed for each image class. When applied to a given image, each COSFIRE filter produces a maximum response value. By concatenating the maximum response across the 50 filters per class, a 200-element descriptor vector is obtained for that image (since there are 4 classes).\n",
        "\n",
        "This process is applied to every image, resulting in a dataframe where each row contains the 200-element descriptor vector corresponding to an image. So each image is represented by a n-dimensional vector (n=200 in this case) of COSFIRE filter response values, which encode visual characteristics that help differentiate between classes.\n",
        "\n",
        "::: {.callout-tip}\n",
        "The dataframe stores these image descriptor vectors, with each row representing a single image and each column representing the maximum response from one of the 200 total COSFIRE filters applied. This serves as the input data capturing image features that will be further transformed into a k-bit hash code for efficient similarity search and retrieval. The compact hash representation helps quickly locate the most similar images from the database given a new query image.\n",
        ":::\n",
        "\n",
        ":::\n"
      ],
      "id": "0e7bd80c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#$Env:QUARTO_PYTHON = \"C:\\Users\\P307791\\Anaconda3\\python.exe\"\n",
        "\n",
        "from cosfire_workflow_utils import *\n",
        "df_training, df_testing, train_label_code, valid_label_code, _ = get_data(r\"G:\\My Drive\\cosfire\\COSFIREdescriptor.mat\")\n",
        "\n",
        "dic_labels = { 2: 'Bent',\n",
        "                3: ' Compact',\n",
        "                 0: 'FRI',\n",
        "                 1: 'FRII'\n",
        "              }\n",
        "\n",
        "#rename 'label_name' to 'label_code'\n",
        "df_training.rename(columns={'label_name': 'label_code'}, inplace=True) \n",
        "df_testing.rename(columns={'label_name': 'label_code'}, inplace=True)         \n",
        "df_training['label_name'] = df_training['label_code'].map(dic_labels)\n",
        "df_testing['label_name'] = df_testing['label_code'].map(dic_labels)\n",
        "\n",
        "data_preview = pd.concat([df_training.iloc[:, :10], df_training[['label_name']]], axis=1).head(10)\n",
        "data_preview.columns = ['descrip_1', 'descrip_2', 'descrip_3', 'descrip_4', 'descrip_5',\n",
        "       'descrip_6', 'descrip_7', 'descrip_8', 'descrip_9', 'descrip_10',\n",
        "       'galaxy']\n",
        "df_training_new = pd.concat([df_training,df_testing], ignore_index=True)\n",
        "\n",
        "\n",
        "df_training.drop('label_name', axis=1, inplace=True)\n",
        "df_testing.drop('label_name', axis=1, inplace=True)\n",
        "\n",
        "\n",
        "\n",
        "display(Markdown(data_preview.to_markdown(index = True)))"
      ],
      "id": "fdeb1ba6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model Training\n",
        "\n",
        "::: {.justify}\n",
        "\n",
        "#### Loss function\n",
        "\n",
        "Let $\\Omega$ represent the COSFIRE descriptor embedding space for radio galaxy images. The objective is to discover a mapping function $F : \\Omega → {+1, −1}^{k}$ that translates the embedding space to a k-bit binary code space. This mapping should be learned in such a way that visually or semantically similar radio galaxy images are assigned binary codes that are close to each other, while dissimilar images are mapped to binary codes that are far apart in the binary code space. \n",
        "\n",
        "\\begin{aligned} \n",
        "L_r\\left(\\mathbf{b}_1, \\mathbf{b}_2, y\\right) & =\\frac{1}{2}(1-y)\\left\\|\\mathbf{b}_1-\\mathbf{b}_2\\right\\|_2^2 \\\\\n",
        " & +\\frac{1}{2} y \\max \\left(m-\\left\\|\\mathbf{b}_1-\\mathbf{b}_2\\right\\|_2^2, 0\\right) \\\\ \n",
        " & +\\alpha\\left(\\left\\|\\left|\\mathbf{b}_1\\right|-\\mathbf{1}\\right\\|_1+\\left\\|\\left|\\mathbf{b}_2\\right|-\\mathbf{1}\\right\\|_1\\right)\n",
        " \\end{aligned}\n",
        "\n",
        "where $D_h(· , ·)$ denotes the Hamming distance between two binary vectors, and m > 0 is a margin threshold parameter.\n",
        "\n",
        "\n",
        "\n",
        "In this loss function: y = 0 if they are similar, and y = 1 otherwise \n",
        "\n",
        "::: {.callout-note}\n",
        "- The first term encourages similar pairs to have small distances - punishes similar images mapped to different binary codes.\n",
        "\n",
        "- The second term  encourages dissimilar pairs to have distances greater than the margin m punishes dissimilar images mapped to close binary codes when their Hamming distance falls below the margin threshold m. Only those dissimilar pairs having their distance within a radius are eligible to contribute to the loss function.\n",
        ":::\n",
        "\n",
        "\n",
        "Suppose that there are N training pairs randomly selected from the training images ${(I_i,1, I_i,2, y_i)|i = 1, ..., N}$, our goal is to minimize the overall loss function:\n",
        "\n",
        "\n",
        "\\begin{gathered}\n",
        "\\mathcal{L}=\\sum_{i=1}^N L\\left(\\mathbf{b}_{i, 1}, \\mathbf{b}_{i, 2}, y_i\\right) \\\\\n",
        "\\text { s.t. } \\mathbf{b}_{i, j} \\in\\{+1,-1\\}^k, i \\in\\{1, \\ldots, N\\}, j \\in\\{1,2\\}\n",
        "\\end{gathered}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "::: {.callout-tip}\n",
        "Regularization: To reduce the discrepancy between Euclidean space and the Hamming space a commonly used relaxation scheme is to utilize sigmoid or tanh function to approximate the thresholding procedure. A regularizer is applied to help obtain real-valued network outputs (from sigmoid/tanh/relu etc) to approach the desired discrete binary-like values (e.g 0,1).\n",
        ":::\n",
        "\n",
        "We train a simple MLP network architecture. By optimizing this loss, the neural network learns to transform the input into a latent feature space that accentuates similarities and differences critical for distinguishing images effectively. The resulting model provides an end-to-end learning pipeline from raw image inputs to a k(36)-bit compact hash code amenable for efficient image retrieval and matching. Our experiments demonstrate the potential of this straightforward architecture and training approach for image hashing.\n",
        "\n",
        "### Binarization and Mean Average Precision (mAP)\n",
        "\n",
        "Mean average precision (mAP) is a commonly used evaluation metric in image retrieval tasks. It measures the average precision across all queries in the dataset. Precision is defined as the number of relevant images retrieved divided by the total number of images retrieved.\n",
        "\n",
        "\n",
        "\n",
        "The formula for MAP is given as:\n",
        "\n",
        "\n",
        "\\begin{equation}\n",
        "\\text{AP} = \\frac{1}{\\text{GTP} }\\sum_{i=1}^{n}\\text{Precision}(i)\\times\\text{Rel}(i),\n",
        "\\end{equation}\n",
        "\n",
        "\\begin{equation}\n",
        "\\text{mAP} = \\frac{1}{N_q }\\sum_{j=1}^{N_q}AP_j,\n",
        "\\end{equation}\n",
        "\n",
        "\n",
        "where AP represents the average precision of one query, with $n$ being the total number of reference images, and $\\text{GTP}$ the  total number of ground truth positives, $\\text{Precision}(i)$ is the precision of the top $i$ ranked reference images and $\\text{Rel}(i)$ is an indicator variable that is 1 if the $i$th image is relevant and 0 otherwise. Finally, the mAP is computed as the average of all AP values obtained for all $N_q$ query images.\n",
        "\n",
        "::: {.callout-tip}\n",
        "\n",
        "- In image retrieval, a query is typically an image, and the task is to retrieve a set of relevant images from a large dataset. The mAP metric is used to evaluate the performance of the retrieval system by comparing the retrieved images to a set of ground-truth relevant images for each query.\n",
        "\n",
        "- mAP takes into account both the relevance and the ranking of the retrieved images. A high mAP score indicates that the retrieval system is able to retrieve a high proportion of relevant images, and that these images are ranked highly in the retrieved set.\n",
        ":::\n",
        ":::\n"
      ],
      "id": "fe1ef5d2"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "class CosfireNet(nn.Module):\n",
        "    def __init__(self, input_size, output_size):\n",
        "        super(CosfireNet, self).__init__()\n",
        "        self.hd = nn.Sequential(\n",
        "            nn.Linear(input_size, 128),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.Tanh(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(64, output_size),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.hd(x)\n",
        "    \n",
        "# Data\n",
        "class CosfireDataset(Dataset):\n",
        "    def __init__(self, dataframe):\n",
        "        self.data = torch.tensor(dataframe.iloc[:, :-1].values, dtype=torch.float32)\n",
        "        self.labels = torch.tensor(dataframe.iloc[:, -1].values, dtype=torch.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx], self.labels[idx]\n",
        "\n",
        "# Hyperparameters\n",
        "input_size = 200\n",
        "output_size = 24\n",
        "learning_rate = 0.01\n",
        "batch_size = 16\n",
        "alpha = 0.0001\n",
        "epochs = 600\n",
        "props = 0.1\n",
        "margin = 24\n",
        "\n",
        "train_df, valid_df = train_test_split(df_training, test_size = props, random_state = 42)\n",
        "\n",
        "train_dataset = CosfireDataset(train_df)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n",
        "\n",
        "valid_dataset = CosfireDataset(valid_df)\n",
        "valid_dataloader = DataLoader(valid_dataset, batch_size = batch_size, shuffle = False)\n",
        "\n",
        "\n",
        "\n",
        "# Instantiate CosfireNet\n",
        "model = CosfireNet(input_size, output_size)\n",
        "\n",
        "def DSHLoss(u, y, alpha, margin):\n",
        "    #alpha = 1e-5  # m > 0 is a margin. The margin defines a radius around X1,X2. Dissimilar pairs contribute to the loss\n",
        "    # function only if their distance is within this radius\n",
        "    m = 2 * margin  # Initialize U and Y with the current batch's embeddings and labels\n",
        "    y = y.int()\n",
        "    # Create a duplicate y_label\n",
        "    y = y.unsqueeze(1).expand(len(y),len(y))\n",
        "    y_label = torch.ones_like(torch.empty(len(y), len(y)))\n",
        "    y_label[y == y.t()] = 0\n",
        "\n",
        "    dist = torch.cdist(u, u, p=2).pow(2)\n",
        "    loss1 = 0.5 * (1 - y_label) * dist\n",
        "    loss2 = 0.5 * y_label * torch.clamp(m - dist, min=0)\n",
        "\n",
        "    B1 = torch.norm(torch.abs(u) - 1, p=1, dim=1)\n",
        "    B2 = B1.unsqueeze(1).expand(len(y), len(y))\n",
        "\n",
        "    loss3 = (B2 + B2.t()) * alpha\n",
        "    minibatch_loss = torch.mean(loss1 + loss2 + loss3)\n",
        "    return minibatch_loss\n",
        "\n",
        "\n",
        "################################################################################\n",
        "\n",
        "\n",
        "\n",
        "################################################################################\n",
        "\n",
        "\n",
        "optimizer = optim.RMSprop(model.parameters(), lr=learning_rate)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.95)\n",
        "\n",
        "# Lists to store training and validation losses\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "# Variables to keep track of the best model\n",
        "#best_val_loss = float('inf')\n",
        "\n",
        "# Training loop\n",
        "\n",
        "\n",
        "for epoch in tqdm(range(epochs), desc='Training Progress', leave=True):\n",
        "    model.train()\n",
        "    total_train_loss = 0.0\n",
        "    for _, (inputs, labels) in enumerate(train_dataloader):\n",
        "        # Before the backward pass, use the optimizer object to zero all of the\n",
        "        # gradients for the variables it will update (which are the learnable\n",
        "        # weights of the model). This is because by default, gradients are\n",
        "        # accumulated in buffers( i.e, not overwritten) whenever .backward()\n",
        "        optimizer.zero_grad()\n",
        "        u = model(inputs)\n",
        "        loss = DSHLoss(u = u, y=labels, alpha = alpha, margin = margin)\n",
        "        # Backward pass: compute gradient of the loss with respect to model parameters\n",
        "        loss.backward()\n",
        "        # Calling the step function on an Optimizer makes an update to its  parameters\n",
        "        optimizer.step()\n",
        "        total_train_loss += loss.item()\n",
        "    #It has been well established that you can achieve increased performance and faster \n",
        "    # training on some problems by using a learning rate that changes during training.\n",
        "    scheduler.step() #optimizer.param_groups[0]['lr']  - updates the lr after every epoch.\n",
        "\n",
        "    # Calculate average training loss\n",
        "    average_train_loss = total_train_loss / len(train_dataloader)\n",
        "    train_losses.append(average_train_loss)\n",
        "\n",
        "\n",
        "    # Validation loop\n",
        "    model.eval()\n",
        "    features = []\n",
        "    total_val_loss = 0.0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for val_inputs, val_labels in valid_dataloader:\n",
        "         \n",
        "            val_outputs = model(val_inputs)\n",
        "            features.append(u)\n",
        "            val_loss = DSHLoss(u = val_outputs, y = val_labels, alpha = alpha, margin = margin)\n",
        "            total_val_loss += val_loss.item()\n",
        "\n",
        "    # Calculate average validation loss\n",
        "    average_val_loss = total_val_loss / len(valid_dataloader)\n",
        "    val_losses.append(average_val_loss)\n",
        "\n",
        "    # Save the model if it is the best so far\n",
        "   #  if average_val_loss < best_val_loss:\n",
        "   #    best_val_loss = average_val_loss\n",
        "   #    model_save_path = 'best_model.pth'\n",
        "   #    torch.save(model, model_save_path)\n",
        "model_save_path = f'best_model_{output_size}_bit.pth'\n",
        "torch.save(model, model_save_path)\n",
        "# Plotting the training and validation loss curves\n",
        "plt.plot(range(1, epochs + 1), train_losses, label='Training Loss')\n",
        "plt.plot(range(1, epochs + 1), val_losses, label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss Curves')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "id": "f76b32c3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "###################################\n",
        "###       Evaluate              ###\n",
        "###################################\n",
        "\n",
        "# Load the best model\n",
        "model = torch.load(model_save_path)\n",
        "model.eval()\n",
        "\n",
        "\n",
        "#################################################################\n",
        "valid_dataset = CosfireDataset(valid_df)\n",
        "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "train_dataset = CosfireDataset(train_df)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
        "#################################################################\n",
        "\n",
        "# Lists to store predictions\n",
        "predictions = []\n",
        "\n",
        "# Perform predictions on the testing set\n",
        "with torch.no_grad():\n",
        "    for train_inputs, _ in tqdm(train_dataloader, desc='Predicting', leave=True):\n",
        "        train_outputs = model(train_inputs)\n",
        "        predictions.append(train_outputs.numpy())\n",
        "\n",
        "# Flatten the predictions\n",
        "flat_predictions_train = [item for sublist in predictions for item in sublist]\n",
        "\n",
        "# Append predictions to the df_testing DataFrame\n",
        "train_df['predictions'] = flat_predictions_train\n",
        "\n",
        "#################################################################\n",
        "\n",
        "# Lists to store predictions\n",
        "predictions = []\n",
        "\n",
        "# Perform predictions on the testing set\n",
        "with torch.no_grad():\n",
        "    for valid_inputs, _ in tqdm(valid_dataloader, desc='Predicting', leave=True):\n",
        "        valid_preds = model(valid_inputs)\n",
        "        predictions.append(valid_preds.numpy())\n",
        "\n",
        "# Flatten the predictions\n",
        "flat_predictions_test = [item for sublist in predictions for item in sublist]\n",
        "\n",
        "# Append predictions to the df_testing DataFrame\n",
        "valid_df['predictions'] = flat_predictions_test\n",
        "################################################################\n",
        "\n",
        "\n",
        "#thresholds = list(range(50,100,0.5))#[30, 50, 55, 65, 70, 85, 90]#)\n",
        "#thresholds = np.linspace(50, 70, 50).tolist()\n",
        "# start = 55.714285714\n",
        "# end = 100\n",
        "# step = 0.408163265306122*10\n",
        "\n",
        "# numbers1 = [start + i * step for i in range(int((end - start) / step) + 1)]\n",
        "\n",
        "# start = 0\n",
        "# end = 55.714285714\n",
        "# step = 0.408163265306122*10\n",
        "\n",
        "# numbers2 =  [start + i * step for i in range(int((end - start) / step) + 1)]\n",
        "\n",
        "\n",
        "#thresholds = numbers2 + numbers1\n",
        "\n",
        "\n",
        "thresholds = list(range(0,100,5))#[30, 50, 55, 65, 70, 85, 90]#)\n",
        "# thresholds = np.linspace(50, 70, 50).tolist()\n",
        "\n",
        "mAP_results = []\n",
        "for _,thresh in enumerate(thresholds):\n",
        "\n",
        "  maP,train_binary, train_label, valid_binary, valid_label = mAP_values(train_df,valid_df,thresh, percentile = True,topk=100)\n",
        "  mAP_results.append(maP)\n",
        "\n",
        "\n",
        "\n",
        "data = {'mAP': mAP_results,\n",
        "        'threshold': thresholds}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Find the index of the maximum mAP value\n",
        "max_map_index = df['mAP'].idxmax()\n",
        "\n",
        "# Retrieve the threshold corresponding to the maximum mAP\n",
        "threshold_max_map = df.loc[max_map_index, 'threshold']\n",
        "\n",
        "maP,train_binary, train_label, valid_binary, valid_label = mAP_values(train_df,valid_df,thresh = threshold_max_map, percentile = True, topk=100)\n",
        "\n",
        "# Plot the line curve\n",
        "plt.plot(thresholds, mAP_results,  linestyle='-',color = 'red')\n",
        "plt.xlabel('Threshold (Percentile)')\n",
        "plt.ylabel('mAP')\n",
        "plt.show()\n",
        "\n",
        "print('The optimal threshold is: ', threshold_max_map)\n",
        "print('The Best Validation mAP is: ',maP)"
      ],
      "id": "0ea526df",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Model Testing\n",
        "\n",
        "Now applying the same model (best model from the validation data) to the test data with the best threshold as per the validation data.\n"
      ],
      "id": "b0474730"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "test_dataset = CosfireDataset(df_testing)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "train_dataset = CosfireDataset(df_training)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "\n",
        "\n",
        "# %%\n",
        "# Lists to store predictions\n",
        "predictions = []\n",
        "\n",
        "# Perform predictions on the testing set\n",
        "with torch.no_grad():\n",
        "    for train_inputs, _ in tqdm(train_dataloader, desc='Predicting', leave=True):\n",
        "        train_outputs = model(train_inputs)\n",
        "        predictions.append(train_outputs.numpy())\n",
        "\n",
        "# Flatten the predictions\n",
        "flat_predictions_train = [item for sublist in predictions for item in sublist]\n",
        "\n",
        "# Append predictions to the df_testing DataFrame\n",
        "df_training['predictions'] = flat_predictions_train\n",
        "\n",
        "#################################################################\n",
        "\n",
        "# Lists to store predictions\n",
        "predictions = []\n",
        "\n",
        "# Perform predictions on the testing set\n",
        "with torch.no_grad():\n",
        "    for test_inputs, _ in tqdm(test_dataloader, desc='Predicting', leave=True):\n",
        "        test_outputs = model(test_inputs)\n",
        "        predictions.append(test_outputs.numpy())\n",
        "\n",
        "# Flatten the predictions\n",
        "flat_predictions_test = [item for sublist in predictions for item in sublist]\n",
        "\n",
        "# Append predictions to the df_testing DataFrame\n",
        "df_testing['predictions'] = flat_predictions_test\n",
        "\n",
        "\n",
        "maP,train_binary, train_label, test_binary, test_label = mAP_values(df_training,df_testing,thresh = threshold_max_map, percentile = True, topk=100)\n",
        "\n",
        "print('At the optimal threshold: ', threshold_max_map)\n",
        "print('The Test mAP is: ',maP)"
      ],
      "id": "bfc07514",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::{.column-page}\n",
        "\n",
        "\n",
        "### Model Predictions overview\n",
        "\n",
        "::: {.panel-tabset}\n",
        "\n",
        "####  Test predictions\n"
      ],
      "id": "a95f7175"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dic_labels_rev = { 2:'Bent',\n",
        "                3:'Compact',\n",
        "                  0:'FRI',\n",
        "                  1: 'FRII'\n",
        "              }\n",
        "\n",
        "df_training['labels'] = df_training['label_code'].map(dic_labels_rev)\n",
        "df_testing['labels'] = df_testing['label_code'].map(dic_labels_rev)\n",
        "# Create a figure and axis\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "\n",
        "# Iterate over label_code values\n",
        "for label_code in range(4):\n",
        "    dff = df_testing.query(f'label_code == {label_code}')\n",
        "    out_array_train = []\n",
        "    dd_train = np.array([out_array_train.extend(np.array(out)) for _, out in enumerate(dff.predictions)])\n",
        "    out_array_train = np.array(out_array_train)\n",
        "    \n",
        "    # Plot the KDE curve with a hue\n",
        "    sns.kdeplot(out_array_train, label=f'{dic_labels[label_code]}', ax=ax)\n",
        "\n",
        "# Set the x-axis limits\n",
        "ax.set_xlim(-1, 1)\n",
        "\n",
        "# Customize the plot\n",
        "ax.set_xlabel('Value')\n",
        "ax.set_ylabel('Density')\n",
        "ax.grid(True)\n",
        "ax.legend()\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n",
        "plt.close()\n",
        "\n",
        "df = pd.DataFrame([df_testing.predictions[0]])\n",
        "df.columns = ['hash_'+str(i) for i in range(36)]\n",
        "df['label'] = df_testing.labels[0]\n",
        "for j in range(1,400,20):\n",
        "   df2 = pd.DataFrame([df_testing.predictions[j]])\n",
        "   df2.columns = ['hash_'+str(i) for i in range(36)]\n",
        "   df2['label'] = df_testing.labels[j]\n",
        "   df = pd.concat([df,df2])\n",
        "\n",
        "display(Markdown(df.to_markdown(index = True)))"
      ],
      "id": "48f5f1a4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "####  Train predictions\n"
      ],
      "id": "993903bc"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Create a figure and axis\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "\n",
        "# Iterate over label_code values\n",
        "for label_code in range(4):\n",
        "    dff = df_training.query(f'label_code == {label_code}')\n",
        "    out_array_train = []\n",
        "    dd_train = np.array([out_array_train.extend(np.array(out)) for _, out in enumerate(dff.predictions)])\n",
        "    out_array_train = np.array(out_array_train)\n",
        "    \n",
        "    # Plot the KDE curve with a hue\n",
        "    sns.kdeplot(out_array_train, label=f'{dic_labels[label_code]}', ax=ax)\n",
        "\n",
        "# Set the x-axis limits\n",
        "ax.set_xlim(-1, 1)\n",
        "\n",
        "# Customize the plot\n",
        "ax.set_xlabel('Value')\n",
        "ax.set_ylabel('Density')\n",
        "ax.grid(True)\n",
        "ax.legend()\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n",
        "plt.close()\n",
        "\n",
        "\n",
        "df = pd.DataFrame([df_training.predictions[0]])\n",
        "df.columns = ['hash_'+str(i) for i in range(36)]\n",
        "df['label'] = df_training.labels[0]\n",
        "for j in range(1,1180,50):\n",
        "   df2 = pd.DataFrame([df_training.predictions[j]])\n",
        "   df2.columns = ['hash_'+str(i) for i in range(36)]\n",
        "   df2['label'] = df_training.labels[j]\n",
        "   df = pd.concat([df,df2])\n",
        "\n",
        "display(Markdown(df.to_markdown(index = True)))"
      ],
      "id": "62458679",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "####  T-SNE projection (Test) \n"
      ],
      "id": "c0cb2ec1"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# %%\n",
        "array_dat = []\n",
        "for i in range(df_testing['predictions'].shape[0]):\n",
        "  array_dat.append(list(df_testing['predictions'].iloc[i]))\n",
        "\n",
        "array_dat = np.array(array_dat)\n",
        "array_dat.shape\n",
        "\n",
        "y = df_testing.labels\n",
        "tsne = TSNE(n_components=2, random_state=42)\n",
        "z = tsne.fit_transform(array_dat)\n",
        "df = pd.DataFrame()\n",
        "df[\"y\"] = y\n",
        "df[\"comp-1\"] = z[:,0]\n",
        "df[\"comp-2\"] = z[:,1]\n",
        "\n",
        "sns.scatterplot(x=\"comp-1\", y=\"comp-2\", hue=df.y.tolist(),\n",
        "                palette=sns.color_palette(\"hls\", 4),\n",
        "                data=df).set(title=\"Model last layer T-SNE projection\")\n",
        "\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "id": "0c252a58",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "####  T-SNE projection (Train) \n"
      ],
      "id": "86aa945e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# %%\n",
        "array_dat = []\n",
        "for i in range(df_training['predictions'].shape[0]):\n",
        "  array_dat.append(list(df_training['predictions'].iloc[i]))\n",
        "\n",
        "array_dat = np.array(array_dat)\n",
        "y = df_training.labels\n",
        "tsne = TSNE(n_components=2, random_state=42)\n",
        "z = tsne.fit_transform(array_dat)\n",
        "df = pd.DataFrame()\n",
        "df[\"y\"] = y\n",
        "df[\"comp-1\"] = z[:,0]\n",
        "df[\"comp-2\"] = z[:,1]\n",
        "\n",
        "sns.scatterplot(x=\"comp-1\", y=\"comp-2\", hue=df.y.tolist(),\n",
        "                palette=sns.color_palette(\"hls\", 4),\n",
        "                data=df).set(title=\"Model last layer T-SNE projection\")\n",
        "\n",
        "\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "id": "c2b8a8f5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "####  T-SNE projection (Test & Train) "
      ],
      "id": "ec55e5dd"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "array_dat = []\n",
        "for i in range(df_training['predictions'].shape[0]):\n",
        "  array_dat.append(list(df_training['predictions'].iloc[i]))\n",
        "\n",
        "for i in range(df_testing['predictions'].shape[0]):\n",
        "  array_dat.append(list(df_testing['predictions'].iloc[i]))\n",
        "array_dat = np.array(array_dat)\n",
        "\n",
        "\n",
        "y = np.array(pd.concat([df_training.labels,df_testing.labels]))\n",
        "tsne = TSNE(n_components=2, random_state=42)\n",
        "z = tsne.fit_transform(array_dat)\n",
        "df = pd.DataFrame()\n",
        "df[\"y\"] = y\n",
        "df[\"comp-1\"] = z[:,0]\n",
        "df[\"comp-2\"] = z[:,1]\n",
        "\n",
        "sns.scatterplot(x=\"comp-1\", y=\"comp-2\", hue=df.y.tolist(),\n",
        "                palette=sns.color_palette(\"hls\", 4),\n",
        "                data=df).set(title=\"Model last layer T-SNE projection\")\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "id": "3e7762a0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### View the image retrieval - COSFIRE Approach"
      ],
      "id": "188503d2"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dic_labels = { 2: 'Bent',\n",
        "                3: ' Compact',\n",
        "                 0: 'FRI',\n",
        "                 1: 'FRII'\n",
        "              }\n",
        "\n",
        "df_training['labels'] = df_training['label_code'].map(dic_labels)\n",
        "df_testing['labels'] = df_testing['label_code'].map(dic_labels)\n",
        "\n",
        "df_labels_paths = pd.DataFrame()\n",
        "df_labels_paths['paths'] = glob.glob('../data/test/*/*')\n",
        "df_labels_paths['label'] = df_labels_paths['paths'].apply(lambda x: x.split(os.path.sep)[1] )\n",
        "dic_labels_rev = { 'Bent':2,\n",
        "                'Compact':3,\n",
        "                  'FRI':0,\n",
        "                  'FRII':1\n",
        "              }\n",
        "df_labels_paths['label_code'] = df_labels_paths['label'].map(dic_labels_rev)\n",
        "df_labels_paths = df_labels_paths.sort_values('label_code')\n",
        "df_labels_paths = df_labels_paths.reset_index()[['paths', 'label', 'label_code']]\n",
        "\n",
        "df_labels_train_paths = pd.DataFrame()\n",
        "df_labels_train_paths['paths'] = glob.glob('../data/train/*/*')\n",
        "df_labels_train_paths['label'] = df_labels_train_paths['paths'].apply(lambda x: x.split(os.path.sep)[1] )\n",
        "df_labels_train_paths['label_code'] = df_labels_train_paths['label'].map(dic_labels_rev)\n",
        "df_labels_train_paths = df_labels_train_paths.sort_values('label_code')\n",
        "df_labels_train_paths = df_labels_train_paths.reset_index()[['paths', 'label', 'label_code']]\n",
        "\n",
        "def perf_percentages(input_data):\n",
        "    unique, counts = np.unique(input_data, return_counts=True)\n",
        "    df = pd.DataFrame()\n",
        "    df['unique'] = unique\n",
        "    df['counts'] = counts\n",
        "    df['Percentage'] = np.round(counts / counts.sum() * 100)\n",
        "    return df\n",
        "\n",
        "    \n",
        "def query_image(test_image_index = 190, \n",
        "test_images_paths = df_labels_paths,\n",
        "train_images_db_paths = df_labels_train_paths,\n",
        "train_images_db = train_binary,\n",
        "test_binary = test_binary):\n",
        "\n",
        "         \n",
        "    print('Test Image is: ', test_images_paths.label[test_image_index])\n",
        "    fig = plt.figure(figsize=(3, 3))\n",
        "    image_test = Image.open(test_images_paths.paths[test_image_index])\n",
        "    image_test = torch.from_numpy(np.array(image_test))\n",
        "    plt.imshow(image_test[:, :, 1], cmap='viridis')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "    test_image = test_binary[test_image_index]  \n",
        "    #np.count_nonzero(np.array([0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1,\n",
        "      # 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0])==np.array([0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
        "      # 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0]))\n",
        "    similarity_distance = np.count_nonzero(test_image != train_images_db, axis=1)\n",
        "    sort_indices = np.argsort(similarity_distance)\n",
        "    top_indices = sort_indices[:100]\n",
        "    #print(top_indices)\n",
        "    paths_to_imgs = [train_images_db_paths.paths[index] for _,index in enumerate(top_indices)]\n",
        "    df = perf_percentages([train_images_db_paths.label[index] for index in top_indices])\n",
        "    print(df)\n",
        "    cols = 8\n",
        "    rows = 4\n",
        "\n",
        "    fig = plt.figure(figsize=(2 * cols, 2 * rows))\n",
        "    for col in range(cols):\n",
        "        for i, img_path in enumerate(paths_to_imgs[:32]):\n",
        "            ax = fig.add_subplot(rows, cols, i + 1)\n",
        "            ax.grid(visible=False)\n",
        "            ax.axis(\"off\")\n",
        "            image = Image.open(img_path)\n",
        "            image = torch.from_numpy(np.array(image))\n",
        "            ax.imshow(image[:, :, 1], cmap='viridis')\n",
        "            ax.set_title(img_path.split(os.path.sep)[1])\n",
        "\n",
        "    plt.show()\n",
        "    \n",
        "\n",
        "\n",
        "#df_testing.labels.value_counts(sort=False)"
      ],
      "id": "779559d0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: {.panel-tabset}\n",
        "\n",
        "#### FRI \n"
      ],
      "id": "5959d1fb"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#0-200\n",
        "\n",
        "#query_image(test_image_index = 5)\n"
      ],
      "id": "13391ccc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "</br>\n"
      ],
      "id": "7f62df1a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "query_image(test_image_index = random.randint(0, 100))"
      ],
      "id": "c6f3a177",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### FRII\n"
      ],
      "id": "acd54d4a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#101-200\n",
        "#query_image(test_image_index =105)\n"
      ],
      "id": "396b68ac",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "</br>\n"
      ],
      "id": "54f348d5"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "query_image(test_image_index = random.randint(101, 202))"
      ],
      "id": "643667dd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Bent\n"
      ],
      "id": "a103a391"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#200 - 300\n",
        "#query_image(test_image_index =250)"
      ],
      "id": "de8ad1f2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "</br>\n"
      ],
      "id": "6a6f2291"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "query_image(test_image_index = random.randint(205, 300))"
      ],
      "id": "c6f4b8de",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Compact\n"
      ],
      "id": "243da3fe"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#300-400\n",
        "#query_image(test_image_index =403)"
      ],
      "id": "4aba7933",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "</br>\n"
      ],
      "id": "286cebb1"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "query_image(test_image_index = random.randint(310, 400))"
      ],
      "id": "6eafde48",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "\n",
        "\n",
        "</br>\n",
        "\n",
        "\n",
        ":::\n",
        ":::"
      ],
      "id": "29949601"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}